Model,Prompt,Tier,Avg_Latency_s,Avg_Tokens_per_s,Avg_CPU_%,Avg_RAM_%,Avg_Temp_C,Accuracy_%,Performance_Score,family,Family,TokensNorm,AccNorm,LatNorm,RAMNorm,CompositeNormScore
qwen3:8b,Write a JSON command that turns on a living room light and sets brightness to 70,tier_3_creative,0.7263624668121338,29.137936816775493,0.35,21.9,57.91229088946588,85.17713426084967,337.04677630722284,qwen,qwen,0.9702116091693813,0.7194750785237234,0.5982979378886206,0.0,0.7842675796471453
qwen3:4b,Explain why smaller language models might be faster but less accurate.,tier_2_reasoning,0.8337130546569824,26.49399766299912,0.3,21.9,58.99928708867712,90.30935291234636,283.58643638380323,qwen,qwen,0.8788270915787824,0.8668751615343591,0.6893181745132179,0.0,0.7737297501891771
qwen3:1.7b,Explain why smaller language models might be faster but less accurate.,tier_2_reasoning,0.1315817832946777,29.07823526262672,1.9,22.0,58.57688124835174,69.4557881153415,1426.491247793864,qwen,qwen,0.9681480980944377,0.2679495523828899,0.09399628812270014,0.04000000000000057,0.7448448473281021
qwen3:4b,Analyze the trade-offs between model size and inference latency on edge devices.,tier_2_reasoning,0.0542237758636474,20.63423103018354,2.5,21.9,57.88413953443701,80.66364074927282,2591.613738952306,qwen,qwen,0.6762914370919948,0.5898451146716615,0.028406110345973516,0.0,0.7417888871691016
qwen3:1.7b,Summarize what a neural network is in one sentence.,tier_1_simple,0.5069036483764648,20.576222052964148,0.25,22.0,61.58559679602942,90.01720458287994,358.3286741933495,qwen,qwen,0.6742864278649305,0.8584845042107063,0.4122235624763611,0.04000000000000057,0.7408152099139118
